{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6c648b6-649b-4d0e-bca9-89c205ab1628",
   "metadata": {},
   "source": [
    "# Copyright 2024 Samarth Singh samarths@bu.edu\n",
    "\n",
    "\"\"\"\n",
    "# Blackjack Helper System: Training and Real-Time Card Recognition\n",
    "\n",
    "## Purpose:\n",
    "This script builds a Blackjack helper system that:\n",
    "1. Trains a ResNet18 model to recognize playing cards (Ace, 2-10, Jack, Queen, King).\n",
    "2. Provides real-time card recognition using OpenCV.\n",
    "3. Dynamically calculates card values and suggests the next move in Blackjack (\"Hit\", \"Stay\", or \"Blackjack\").\n",
    "\n",
    "## Workflow:\n",
    "1. **Dataset Download**:\n",
    "   - The script automatically downloads the `cards-image-datasetclassification` dataset from KaggleHub.\n",
    "   - The dataset is split into training, validation, and testing sets.\n",
    "\n",
    "2. **Training**:\n",
    "   - A pretrained ResNet18 model (from ImageNet) is fine-tuned on the card dataset.\n",
    "   - The model predicts card classes (`13` classes for cards: Ace, 2-10, Jack, Queen, King).\n",
    "   - Best-performing model is saved as `resnet_best_model.pth`.\n",
    "\n",
    "3. **Testing**:\n",
    "   - Evaluates the model on the test dataset.\n",
    "   - Outputs the overall accuracy of the model.\n",
    "\n",
    "4. **Real-Time Card Recognition**:\n",
    "   - Captures live video using OpenCV.\n",
    "   - Draws an ROI box where the player places the card.\n",
    "   - Recognizes the card inside the ROI when the spacebar is pressed.\n",
    "   - Updates the player's total card value.\n",
    "   - Suggests the next move in Blackjack: \"Hit\", \"Stay\", or \"Blackjack\".\n",
    "   - If \"Stay\" is suggested, it shows the total value and stops processing further cards.\n",
    "\n",
    "---\n",
    "\n",
    "## Libraries Used:\n",
    "1. **PyTorch**:\n",
    "   - `torch`: Core library for deep learning models.\n",
    "   - `torchvision`: Provides pre-trained ResNet18 and transformations for image data.\n",
    "\n",
    "2. **OpenCV**:\n",
    "   - Used for capturing video, defining the Region of Interest (ROI), and real-time display of predictions.\n",
    "\n",
    "3. **TQDM**:\n",
    "   - Provides progress bars for training and testing loops.\n",
    "\n",
    "4. **PIL**:\n",
    "   - Converts OpenCV images into a format suitable for PyTorch preprocessing.\n",
    "\n",
    "5. **Matplotlib**:\n",
    "   - Displays pop-up suggestions for Blackjack moves.\n",
    "\n",
    "6. **KaggleHub**:\n",
    "   - Downloads the card dataset from Kaggle with a single command.\n",
    "\n",
    "---\n",
    "\n",
    "## How to Use:\n",
    "1. Install required libraries:\n",
    "   ```bash\n",
    "   pip install torch torchvision tqdm opencv-python matplotlib kagglehub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25199ee-de90-4a05-9887-4703e5b0ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub  # For downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a835eb7-1659-49f3-a069-f7ef5ae36509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# Step 1: Download the Dataset\n",
    "# ----------------------------------------------\n",
    "\n",
    "print(\"Downloading dataset...\")\n",
    "# Downloads the dataset from KaggleHub and sets the dataset path\n",
    "dataset_path = kagglehub.dataset_download(\"gpiosenka/cards-image-datasetclassification\")\n",
    "print(\"Path to dataset files:\", dataset_path)\n",
    "\n",
    "# Define dataset folder paths for train, validation, and test sets\n",
    "train_dir = os.path.join(dataset_path, \"train\")\n",
    "val_dir = os.path.join(dataset_path, \"valid\")\n",
    "test_dir = os.path.join(dataset_path, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a5c909-de67-4052-8c4a-fb31da3d0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# Step 2: Define Data Transformations\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Data transformations for training: Augmentation techniques are applied\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resizes images for ResNet\n",
    "    transforms.RandomHorizontalFlip(),  # Adds random horizontal flips\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),  # Adjust brightness, contrast\n",
    "    transforms.RandomRotation(15),  # Random rotation for diversity\n",
    "    transforms.ToTensor(),  # Converts image to tensor\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalizes to match ImageNet stats\n",
    "])\n",
    "\n",
    "# Data transformations for validation and test: No augmentation, just resizing and normalization\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4815e16-622d-4eee-9b41-c83d3c290bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# Step 3: Load Dataset and DataLoader\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Create datasets for training, validation, and testing\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=test_transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=test_transform)\n",
    "\n",
    "# Create DataLoader for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Get the class names from the dataset\n",
    "class_names = train_dataset.classes\n",
    "print(f\"Classes: {class_names}\")\n",
    "num_classes = len(class_names)  # Number of output classes (13 for cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e8c637-efb7-45a9-8aae-42534b4c5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# Step 4: Load ResNet18 Model\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Load ResNet18 pretrained on ImageNet\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet18(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "# Modify the final fully connected layer to match the number of card classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)  # Send the model to the available device (CPU/GPU)\n",
    "\n",
    "# Set up optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d27c24-ecc1-4f13-9080-c0847884f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# Step 5: Train the Model\n",
    "# ----------------------------------------------\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Function to train the ResNet model on the training dataset.\n",
    "    Args:\n",
    "        model: ResNet18 model.\n",
    "        train_loader: DataLoader for the training dataset.\n",
    "        val_loader: DataLoader for the validation dataset.\n",
    "        criterion: Loss function.\n",
    "        optimizer: Optimizer.\n",
    "        num_epochs: Number of training epochs.\n",
    "    \"\"\"\n",
    "    best_accuracy = 0.0  # Tracks the best validation accuracy\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0  # Track cumulative loss\n",
    "        correct_train = 0  # Track correct predictions\n",
    "        total_train = 0  # Track total samples\n",
    "\n",
    "        # Loop through the training dataset\n",
    "        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", unit=\"batch\")\n",
    "        for images, labels in train_loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Calculate loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update model parameters\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_train += (preds == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "            train_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        train_accuracy = correct_train / total_train\n",
    "\n",
    "        # Validate the model\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\", unit=\"batch\")\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loop:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_val += (preds == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "                val_loop.set_postfix(accuracy=correct_val / total_val)\n",
    "\n",
    "        val_accuracy = correct_val / total_val\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Save the model if validation accuracy improves\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            model_save_path = \"resnet_best_model.pth\"\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Model saved at: {model_save_path}\")\n",
    "\n",
    "    print(\"Training complete. Best accuracy: {:.4f}\".format(best_accuracy))\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383d366-9d24-4de1-b95b-b3f598f4eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# Step 6: Test the Model\n",
    "# ----------------------------------------------\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Function to test the trained model on the test dataset.\n",
    "    Args:\n",
    "        model: Trained ResNet18 model.\n",
    "        test_loader: DataLoader for the test dataset.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Load the best model and test it\n",
    "model.load_state_dict(torch.load(\"resnet_best_model.pth\"))\n",
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbebb155-b580-4a98-98cc-f9053c7fe044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# Step 7: Real-Time Card Recognition with OpenCV\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Real-time card recognition logic\n",
    "# Set up optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_accuracy = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", unit=\"batch\")\n",
    "        for images, labels in train_loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_train += (preds == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "            train_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        train_accuracy = correct_train / total_train\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\", unit=\"batch\")\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loop:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_val += (preds == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "                val_loop.set_postfix(accuracy=correct_val / total_val)\n",
    "\n",
    "        val_accuracy = correct_val / total_val\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), \"resnet_best_model.pth\")\n",
    "    print(\"Training complete. Best accuracy: {:.4f}\".format(best_accuracy))\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n",
    "\n",
    "# Test function\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Load the best model and test it\n",
    "model.load_state_dict(torch.load(\"resnet_best_model.pth\"))\n",
    "print(\"Trained model saved at: resnet_best_model.pth\")\n",
    "test_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b435a-db64-4a96-898c-0c8b4239cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time card recognition using OpenCV\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "def get_card_value(card_name, current_total):\n",
    "    if card_name == \"Ace\":\n",
    "        return 11 if current_total + 11 <= 21 else 1\n",
    "    return int(card_name)\n",
    "\n",
    "def blackjack_suggestion(total):\n",
    "    if total == 21:\n",
    "        return \"Blackjack! Stay!\"\n",
    "    elif total >= 17:\n",
    "        return \"Stay\"\n",
    "    else:\n",
    "        return \"Hit\"\n",
    "\n",
    "# OpenCV part\n",
    "cap = cv2.VideoCapture(0)\n",
    "player_total = 0\n",
    "last_card_label = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    box_start, box_end = (200, 100), (450, 350)\n",
    "    cv2.rectangle(frame, box_start, box_end, (0, 255, 0), 2)\n",
    "\n",
    "    if last_card_label:\n",
    "        cv2.putText(frame, f\"Last Card: {last_card_label}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        roi = frame[box_start[1]:box_end[1], box_start[0]:box_end[0]]\n",
    "        image = Image.fromarray(roi).convert(\"RGB\")\n",
    "        image = test_transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image)\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            last_card_label = class_names[pred.item()]\n",
    "            player_total += get_card_value(last_card_label, player_total)\n",
    "\n",
    "        suggestion = blackjack_suggestion(player_total)\n",
    "        print(f\"Suggestion: {suggestion}\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5674ae8-eed9-4456-b3f5-a026001e64fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
